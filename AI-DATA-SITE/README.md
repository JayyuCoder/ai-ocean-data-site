# AI Ocean Data Site

Real-time coral reef health monitoring using AI, NOAA data, and machine learning.

## ğŸ—ï¸ Architecture

```
NOAA CRW API â”€â”€â”
               â”œâ”€â”€â–º Data Ingestion (6 AM)
Allen Coral â”€â”€â”€â”¤
               â””â”€â”€â–º Data Pipeline
                    â”‚
                    â”œâ”€â”€â–º Cleaning + Transformation
                    â”œâ”€â”€â–º PostGIS Spatial Merge
                    â””â”€â”€â–º ML Pipeline
                         â”œâ”€â”€ LSTM Forecasting
                         â””â”€â”€ Anomaly Detection
                         â”‚
                         â””â”€â”€â–º PostgreSQL + PostGIS
                              â”‚
                              â”œâ”€â”€â–º FastAPI Backend
                              â””â”€â”€â–º Streamlit Dashboard
```

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.10+
- PostgreSQL + PostGIS

### Installation

1. **Clone & Setup**
```bash
cd AI-DATA-SITE
pip install -r requirements.txt
```

2. **Configure Environment**
```bash
cp .env.example .env
# Edit .env with your credentials
```

3. **Docker Deployment**
```bash
docker-compose up -d
```

This starts:
- PostgreSQL + PostGIS on port 5432
- FastAPI Backend on port 8000
- Scheduler service (6 AM daily)

4. **Frontend Dashboard**
```bash
streamlit run frontend/app.py
```

Access at `http://localhost:8501`

## ğŸ› ï¸ Lightweight Scheduler & Services

This repo includes a lightweight scheduler that will run the pipeline daily.

To start all services (backend, frontend, scheduler) in background:

```bash
./scripts/run_services.sh
```

If you don't want the full TensorFlow/Postgres pipeline, the scheduler will automatically prefer the `run_pipeline_light.py` runner which uses only local SQLite and lighter deps.

## ğŸš¢ Local Monitoring with Docker Compose

To run Prometheus + Grafana locally (provisioned to scrape the app and metrics server):

```bash
cd deploy
docker-compose -f docker-compose-grafana.yml up -d
```

Grafana: http://localhost:3000 (admin/admin)
Prometheus: http://localhost:9090

The Grafana dashboard is pre-provisioned and will appear after Grafana starts.

## âš™ï¸ Automated Kubernetes Deploy

To enable automated deploys to your Kubernetes cluster, set a repository secret `KUBE_CONFIG` containing your kubeconfig file base64-encoded.

Then pushes to `main` will trigger `.github/workflows/deploy-to-k8s.yml` which applies manifests under `deploy/k8s/`.


## ğŸ“Š Project Structure

```
AI-DATA-SITE/
â”œâ”€â”€ pipeline/              # Data fetching & processing
â”‚   â”œâ”€â”€ fetch_noaa.py      # NOAA CRW API (SST, pH, DHW)
â”‚   â”œâ”€â”€ fetch_allen.py     # Allen Coral Atlas
â”‚   â”œâ”€â”€ clean_transform.py # Data cleaning
â”‚   â”œâ”€â”€ merge_data.py      # PostGIS spatial merge
â”‚   â””â”€â”€ run_pipeline.py    # Master orchestrator
â”‚
â”œâ”€â”€ ml/                    # Machine Learning
â”‚   â””â”€â”€ model.py           # LSTM + Anomaly Detection
â”‚
â”œâ”€â”€ backend/               # FastAPI API
â”‚   â”œâ”€â”€ main.py            # API endpoints
â”‚   â”œâ”€â”€ database.py        # PostgreSQL connection
â”‚   â””â”€â”€ models.py          # SQLAlchemy ORM models
â”‚
â”œâ”€â”€ frontend/              # Streamlit Dashboard
â”‚   â””â”€â”€ app.py             # Interactive visualization
â”‚
â”œâ”€â”€ scheduler/             # Daily Pipeline Trigger
â”‚   â””â”€â”€ scheduler.py       # 6 AM APScheduler
â”‚
â”œâ”€â”€ Dockerfile             # Container image
â”œâ”€â”€ docker-compose.yml     # Multi-service orchestration
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸ”Œ API Endpoints

### GET /
Health check & service info

### GET /health
Server status

### GET /data/latest
Latest ocean metrics

### GET /data/timeseries?days=30
Historical time-series data

### GET /data/anomalies
Detected anomalies

### GET /stats
Aggregate statistics

## ğŸ“ˆ ML Models

### 1. Health Score
```
score = reef_baseline - (SST Ã— 1.5 + DHW Ã— 5)
```

### 2. LSTM Forecasting
- **Input**: 30-day time window
- **Output**: 7-day pH/SST forecast
- **Architecture**: 64â†’32 LSTM layers + Dense

### 3. Anomaly Detection
- **Algorithm**: Isolation Forest
- **Contamination**: 10%
- **Input**: SST/pH series

## â˜ï¸ Cloud Deployment

### AWS
```
EC2 (Docker) â†’ RDS (PostgreSQL+PostGIS)
EventBridge (6 AM trigger) â†’ Lambda (Pipeline)
S3 (NOAA files)
CloudWatch (Monitoring)
```

### Azure
```
AKS (Kubernetes) â†’ Azure PostgreSQL
Azure Data Factory (Scheduler)
Blob Storage (Data lake)
Application Insights (Monitoring)
```

## ğŸ“ IEEE Project Report Structure

1. **Abstract** - Brief overview of system & results
2. **Introduction** - Problem statement, motivation
3. **Related Work** - Similar projects, literature review
4. **Data Sources**
   - NOAA Coral Reef Watch (SST, DHW)
   - Allen Coral Atlas (Reef shapes)
   - Global Ocean Acidification Network (pH)
5. **System Architecture** - Pipeline diagram, components
6. **Data Pipeline**
   - Ingestion, cleaning, transformation
   - PostGIS spatial merging
7. **ML Models**
   - LSTM architecture & training
   - Anomaly detection methodology
8. **Experimental Results**
   - Model accuracy, precision, recall
   - Forecast validation
9. **Dashboard Visualization**
   - Real-time monitoring
   - Interactive maps
10. **Conclusion & Future Work**

### Keywords
Ocean Health Monitoring, Coral Bleaching, LSTM, PostGIS, NOAA CRW, Machine Learning, Real-time AI Dashboard, Time-Series Forecasting

## ğŸ”§ Configuration

### Database Schema
```sql
CREATE TABLE ocean_metrics (
  id SERIAL PRIMARY KEY,
  date DATE,
  latitude FLOAT,
  longitude FLOAT,
  sst FLOAT,
  dhw FLOAT,
  ph FLOAT,
  health_score FLOAT,
  anomaly BOOLEAN,
  forecast_ph FLOAT
);
```

### PostGIS Spatial Tables
```sql
CREATE TABLE coral_reefs (
  id SERIAL PRIMARY KEY,
  reef_type TEXT,
  geom GEOMETRY(POLYGON, 4326)
);
```

## ğŸ“Š Dashboard Features

- **ğŸ“ Real-time Map**: Interactive Pydeck visualization
- **ğŸ“ˆ Time-Series Charts**: SST, pH, Health trends
- **âš ï¸ Anomaly Detection**: Highlighted warnings
- **ğŸ“Š Statistics**: Aggregate metrics & KPIs
- **ğŸ¯ Predictions**: 7-day forecasts

## ğŸ› ï¸ Development

### Running Locally
```bash
# Terminal 1: Backend
uvicorn backend.main:app --reload

# Terminal 2: Scheduler
python scheduler/scheduler.py

# Terminal 3: Frontend
streamlit run frontend/app.py
```

### Testing Pipeline
```bash
python pipeline/run_pipeline.py
```

## ğŸ“œ License

MIT

## ğŸ‘¥ Contributors

AI Ocean Data Team

---

ğŸŒŠ **Real-time Coral Reef Health Monitoring with AI**
